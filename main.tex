\documentclass{article}
\usepackage[utf8]{inputenc}

\title{BEDU Procesamiento de datos}
\author{María  Magdalena Castro}
\date{July 2021}

\begin{document}
\maketitle
\section{P1. Fundamentos de Python}
- Identificación de un problema. Esta es la justifcación del problema a resolver y porque vale la pena resolverlo o entender mejor el problema.\\
- Investigación al respecto del problema para tener un entendimiento cabal del problema y realizar un documento. \\
- Búsqueda de soluciones anteriores para conocer lo que se ha hecho, entender mejor el problema y plantearnos mejores preguntas. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{P2. Estructura de datos y funciones}
Ya que hemos identificado un problema y que lo entendemos a profundidad, el siguiente paso es del Planteamiento de Preguntas.\\
Básicamente, la persona que lo subió a la plataforma estaba pensando comprar una propiedad (una unidad de 2 recámaras) en la zona pero sabía que había una cosa importante que tomar en cuenta: En ese momento estaba sucediendo lo que se llama una "burbuja" en el mercado.\\
Esta "burbuja" estaba causando que los precios de las propiedades se inflaran mucho más de lo que era su valor "real". Como todas las burbujas, eventualmente tenía que reventar (parece ser que sucedió a finales del 2018) y esta persona quería saber si alguien podría predecir cuándo iba a suceder eso.\\
Tenemos entonces:\\
Un Problema:\\
Quiero comprar una propiedad de dos recámaras pero hay una burbuja en el mercado de bienes raíces y sé que algo problemático puede suceder.
Una serie de Preguntas:\\
a) ¿Cuáles son los mejores suburbios para comprar propiedades en ellos en este momento?\\
b) ¿Cómo han cambiado los precios a través del tiempo? ¿Hay alguna relación entre los cambios de precio y el paso del tiempo?\\
c) ¿Estamos en una "burbuja"? Si es así, ¿hay manera de predecir cuándo va a terminar?\\
d) ¿Podemos saber si una propiedad está siendo vendida al "precio que le corresponde" o si está siendo inflada fuera de proporción?\\
e) ¿Cuáles son las zonas más caras de la ciudad? ¿Se puede saber por qué?\\
f) ¿Hay alguna relación entre las temporadas del año y los precios de las casas?\\
g) ¿Hay alguna relación entre el número de recámaras y el precio de una propiedad?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{P3. Porgramación funcional}
La Colección de Datos. Para poder responder a las preguntas que hemos planteado, es absolutamente necesario tener datos que podamos analizar. Estos datos pueden provenir de diversas fuentes. \\
Normalmente el primer paso es buscar si alguien ya ha recopilado los datos que necesitamos.\\
Si nadie lo ha hecho, toca ver si es posible recabarlos de alguna página web que los tenga pero no en formato descargable. Esto es lo que se llama Web Scraping.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{P4. Pandas}
En este Postwork vamos a empezar a analizar nuestro conjunto de datos usando pandas. Sé que hasta ahora sólo hemos revisado cómo leer archivos tipo JSON usando pandas. El módulo está diseñado para aprender los diferentes tipos de formatos y explorar nuevas fuentes de datos en el momento en el que sean más apropiadas.\\
En caso de que tu dataset tenga algún formato distinto a JSON, pídele ayuda a tu experto para que te guíe rápidamente en el proceso de lectura de tus datos.\\
¿El conjunto de datos que tengo realmente me sirve para responder algunas de las preguntas que me planteé?\\
¿Qué tamaño tiene mi conjunto de datos? ¿Serán datos suficientes?\\
¿Qué columnas tengo y qué información tengo en cada una de esas columnas?\\
Los nombres que tienen mis columnas, ¿son el nombre más apropiado?\\
¿Qué tipos de datos tengo en cada columna? ¿Parecen ser el tipo correcto de datos? ¿O es un tipo de datos "incorrecto"?\\
Si selecciono algunas filas al azar y las observo, ¿estoy obteniendo los datos que debería? ¿o hay datos que parecen estar "sucios" o "incorrectos"?
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{P5. Funciones vectorizadas}
Ya que tenemos nuestro dataset en un DataFrame y que hemos realizado una primera exploración, ha llegado la hora de hacer un poco de limpieza. Limpiar tu DataFrame es sumamente importante para poder utilizarlo después de manera cómoda y apropiada. También vamos a explorar nuestro dataset usando agregaciones para ver si podemos empezar a responder algunas de las preguntas que nos hemos planteado. Los pasos que debes de seguir son los siguientes:\\
Explora tu dataset con el fin de encontrar los NaNs que contiene. Piensa en la distribución de NaNs por columna y por fila.\\
Piensa cuáles son los procedimientos que puedes aplicar a tus NaNs.\\ ¿Tenemos que eliminar las filas/columnas que tienen esos NaNs? ¿O podríamos rellenar esos NaNs con algún valor de manera que podamos retener esas filas/columnas?\\
Limpia tu dataset de manera que no quede ningún NaN.\\
Reindexa tu dataset si lo consideras necesario.\\
Renombra tus columnas si lo consideras necesario.\\
Prueba aplicar agregaciones a tu DataFrame para ver si puedes empezar a responder algunas de las preguntas que te planteaste anteriormente. Aquí tienes una lista de algunas de las funciones que puedes utilizar para agregar/reducir tu dataset: IMG Si tienes cualquier duda, ¡pregúntale a tu experto!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{P6. API}
En este Postwork vamos a dejar descansar un poquito nuestro dataset. La única manera de entender a la perfección cómo utilizar APIs es usándolas. Y eso es lo que vamos a hacer. Vamos a elegir un API y construir un nuevo dataset utilizando peticiones HTTP y concatenaciones. Puede que sea un API que complemente tu dataset original (eso sería lo mejor de lo mejor), o puede simplemente que sea un API que ofrezca información que te parezca interesante. Los pasos a seguir son estos:\\
Encuentra un API que quieras explorar. Puedes encontrar una lista enorme de APIs gratuitas aquí.\\
Crea una cuenta si es necesario.\\
Lee la documentación.\\
Realiza algunas peticiones de prueba para entender la estructura de los datos (si quieres explorar un poco, puedes intentar hacer peticiones usando este software).\\
Automatiza el proceso de realizar peticiones para obtener un dataset considerablemente grande.\\
Explora y limpia tu dataset.\\
Si has encontrado un dataset que complementa la información de tu dataset original (el que has estado trabajando durante todas las sesiones), ve si puedes unirlos en solo DataFrame que incluya la información útil de ambos.\\
Extra: Puedes también explorar la posibilidad de automatizar algunos de los procesos de limpieza que has realizado con tu dataset. Si encuentras dónde podría ser útil y te animas a hacerlo, recuerda proteger tu código con estructuras try except para que la automatización no falle.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{P7. Transformación, filtración y reordenamiento}
Ha llegado el momento de aplicar técnicas comunes de procesamiento de datos a nuestro conjunto de datos. Para este momento ya debes de tener un conjunto de datos que te sea interesante y que haya sido limpiado previamente de NaNs. También es importante que ya hayas explorado extensivamente tu dataset para que lo conozcas muy bien. De igual manera, es recomendable que tu dataset esté bien indexado y que tenga nombres coherentes y comprensibles para las columnas.\\
Para aplicar en tu dataset lo que vimos en esta sesión, realiza las siguientes acciones:\\
Checa que todos tus datos tengan el tipo de dato correcto. Si no es así, usa casting para convertir tus datos al tipo de dato correcto (recuerda que tipos de dato como datetime64 se guardan como strings cuando están en archivos .csv, así que tendrás que convertirlos al tipo de dato apropiado cada vez que importes tu archivo.)\\
Si tienes columnas de texto, asegúrate de que todas tengan el formato correcto. Si no es así, utiliza las técnicas de manipulación de strings para darles el formato que necesitas.\\
Si consideras que alguna de tus columnas sería más clara si los datos tuvieran otro formato o representación usa map para transformar los datos de esa columna.\\
Si crees que es posible generar nuevas columnas útiles a partir de las columnas que ya tienes, usa apply para generar nuevos datos a partir de los que tienes y añádelos a tu dataset.\\
Con el fin de responder algunas de las preguntas que te planteaste acerca de tu dataset, usa filtros y sorting para crear nuevos subconjuntos y reordenamientos que sean más adecuados para responder tus preguntas. Primero comienza intentando responder las preguntas que te planteaste al principio, pero después puedes solamente explorar para ver si encuentras otras preguntas que no te habías planteado anteriormente.
Comparte tus dudas y hallazgos con tus compañeros y con la experta, de manera que todos puedan nutrirse mutuamente de su trabajo.
¡Bonne chance!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{P8. Bases de datos, merge y agrupaciones}
Este módulo se llamó Procesamiento de Datos con Python. Eso significa que nuestro objetivo era aprender a adquirir, leer, explorar, limpiar, transformar y estructurar un conjunto de datos para prepararlo para su futuro análisis y visualización. Hasta ahora seguramente habrás realizado ya gran parte de esos procesos. Lo que toca ahora es embellecerlos y ordenarlos.\\
Este último Postwork tiene 2 Partes:\\
La primera parte consiste en tomar todo lo que hemos hecho hasta ahora y colocarlo limpio y ordenado en un Jupyter Notebook. Una de las maravillas de los Jupyter Notebooks es que nos permiten intercalar texto con código, de manera que podamos ir "guiando" al lector a través de nuestro hilo de pensamiento. Bueno, imagina que quieres explicarle a alguien todo lo que has hecho usando solamente un Jupyter Notebook. No puedes hablar con esta persona ni aclararle cosas: todo debe de estar clarificado en el Notebook. Para embellecer un poco tus celdas de texto, puedes usar lenguaje Markdown. Asegúrate de empezar con una introducción donde hables acerca del tema que te llamó la atención. Explica por qué quisiste abordar este tema, cuáles fueron tus preguntas iniciales, y el problema que te gustaría resolver.\\
La segunda parte consiste en hacer planes para el futuro. El Procesamiento de Datos es sólo la fase "preparatoria". Después siguen las tres fases que le terminan de dar forma a todo proyecto de Ciencia de Datos: Análisis Estadístico, Visualización y Predicción/Inferencia. Esta última fase (Predicción) no siempre está presente y no siempre es necesaria. Pero el Análisis Estadístico y la Visualización son partes intrínsecas de la Ciencia de Datos. La segunda parte de este Postwork consiste en hacer planes a futuro. Piensa qué puedes hacer con los datos que tienes. ¿Qué te gustaría analizar? ¿Qué información está disponible en tus datos? ¿Cómo podrías ayudarte a entender mejor los datos usando gráficas y visualizaciones? Haz una lista de tus planes a futuro. Seguramente esa lista irá cambiando conforme avances en el siguiente módulo, pero es un gran comienzo para tener una dirección clara.
¡Felicidades y mucha suerte! ¡Esperamos verte en el próximo módulo de Análisis Estadístico y Visualización!
\end{document}
